CS370 Operating Systems
Colorado State University
Yashwant K Malaiya
Spring 20 L18
Main Memory
Slides based on 
• Text by Silberschatz, Galvin, Gagne
• Various sources
1 1
FAQ
• Page (block of info) vs Frame (block of physical memory)
• Each process has its own page table? Can there be a 
conflict in sharing physical memory? No, unless..
• Can the page table dynamically change?
• Where is the page table?
• Where is the TLB ? On the same chip as CPU. 
2
FAQ
3
Address Translation Scheme
• Address generated by CPU is divided into:
– Page number (p) – used as an index into a page 
table which contains base address of each page in 
physical memory
– Page offset (d) – combined with base address to 
define the physical memory address that is sent to 
the memory unit
page number page offset
p d
m -n n
– For given logical address space 2m and page size
2n
4
Paging Hardware
Page number  p  to frame number   f
5
Paging Hardware With TLB
TLB: uses content addressable memory.
TLB Miss: page table access may be 
done using hardware or software
6
Effective Access Time
• Associative Lookup = e time units
– Can be < 10% of memory access time
• Hit ratio = a
– Hit ratio – percentage of times that a page number is 
found in the associative registers; ratio related to 
number of associative registers
• Effective Access Time (EAT): probability 
weighted
EAT = (100 + e) a + (200+e)(1 – a)
• Ex:
Consider a = 80%, e = negligible for TLB search, 
100ns for memory access
– EAT = 100x0.80 + 200x0.20 = 120ns
• Consider more realistic hit ratio ->  a = 99%, 
– EAT = 100x0.99 + 200 x 0.01 = 101ns
7
Memory Protection
• Memory protection implemented by associating 
protection bit with each frame to indicate if 
read-only or read-write access is allowed
– Can also add more bits to indicate page execute-
only, and so on
• Valid-invalid bit attached to each entry in the 
page table:
– “valid” indicates that the associated page is in the 
process’ logical address space, and is thus a legal 
page
– “invalid” indicates that the page is not in the 
process’ logical address space
• Any violations result in a trap to the kernel
8
Valid (v) or Invalid (i) Bit In A Page Table
“invalid” : page is not 
in the process’s 
address space. 
9
Shared Pages among Processes
• Shared code
– One copy of read-only (reentrant non-self modifying) 
code shared among processes (i.e., text editors, 
compilers, window systems)
– Similar to multiple threads sharing the same 
process space
– Also useful for interprocess communication if 
sharing of read-write pages is allowed
• Private code and data
– Each process keeps a separate copy of the 
code and data
– The pages for the private code and data can 
appear anywhere in the logical address space
10
Shared Pages Example: 3 Processes
How are “pages” shared? 
Include in address space 
of both processes.
ed1, ed2, ed3
(3, 4, 6) shared
11
Overheads in paging:   Page table and internal fragmentation 
Optimal Page Size Problem: 
page table size vs internal  fragmentation tradeoff
• Given
– Average process size = s
– Page size = p
– Size of each entry in page table = e 
• We get for an average process
– Pages per process = s/p 
– se/p: Total page table space
• Total Overhead = Page table overhead + Internal 
fragmentation loss 
= se/p + p/2 
12
Optimal Page size: Page table and internal fragmentation 
• Total Overhead = se/p + p/2
• Optimal: Obtain derivative of overhead with 
respect to p, equate to 0 
-se/p2 +1⁄2 = 0 
• i.e.     p2 =2se    or p = (2se)0.5
Assume  process s = 128KB , e=8 bytes per entry 
• Optimal page size = 1448 bytes
– In practice we will never use 1448 bytes 
– Instead, either 1K or 2K would be used 
• Why? Pages sizes are in powers of 2 i.e. 2X
• Deriving offsets and page numbers is also easier 
13
Page Table Size
• Memory structures for paging can get huge 
using straight-forward methods
– Consider a 32-bit logical address space as on recent 
processors 64-bit on 64-bit processors
– Page size of 4 KB (212) entries
– Page table would have 1 million entries (232 / 212)
– If each entry is 4 bytes -> 4 MB of physical address 
space / memory for page table alone
• That amount of memory used to cost a lot
• Don’t want to allocate that contiguously in main memory
210 1024  or 1 kibibyte
220 1M mebibyte
230 1G      gigibyte
240 1T       tebibyte
15
Issues with large page tables 
• Cannot allocate page table contiguously in 
memory   
• Solutions: 
– Divide the page table into smaller pieces 
– Page the page-table 
• Hierarchical Paging
16
Hierarchical Page Tables
• Break up the logical address space into multiple 
page tables
– A simple technique is a two-level page table
– We then page the page table divide the page table into pages
P1: indexes the outer page table
P2:  page table: maps to frame
17
Two-Level Page-Table Scheme
18
Two-Level Paging Example
• A logical address (on 32-bit machine with 1K page 
size) is divided into:
– a page number consisting of 22 bits
– a page offset consisting of 10 bits
• Since the page table is paged, the page number is 
further divided into:
– a 12-bit page number 
– a 10-bit page offset
• Thus, a logical address is as follows:
• where p1 is an index into the outer page table, and pis the displacement within the page of the inner page2 
table
• Known as forward-mapped page table
19
Two-Level Paging Example
• A logical address is as follows:
• One Outer page table: size 212
– Each entry points to a page of the inner page table
• Often only some of all possible 212 Page 
tables may be needed (each of size 210)
20
Hierarchical Paging
If there is a hit in the TLB (say 95% of the time), then average 
access time will be close to slightly more than one memory 
access time.
21
64-bit Logical Address Space
! Even two-level paging scheme not sufficient
! If page size is 4 KB (212)
! Then page table has 252 entries
! If two level scheme, inner page tables could be 210 4-byte 
entries
! Address would look like
! Outer page table has 242 entries or 244 bytes
! One solution is to add a 2nd outer page table
!But in the following example the 2nd outer page table is still 234 bytes 
in size
4And possibly 4 memory access to get to one physical memory 
location!
22 Full 64 bit physical memories not common yet
Three-level Paging Scheme
• Outer page table has 242 entries!
• Divide the outer page table into 2 levels
• 4 memory accesses!
23
Hashed Page Tables
• Common in address spaces > 32 bits
• The virtual page number is hashed into a page table
– This page table contains a chain of elements hashing to the 
same location
• Each element contains (1) the virtual page number (2) 
the value of the mapped page frame (3) a pointer to the 
next element
• Virtual page numbers are compared in this chain 
searching for a match
– If a match is found, the corresponding physical frame is 
extracted
• Variation for 64-bit addresses is clustered page tables
– Similar to hashed but each entry refers to several pages (such 
as 16) rather than 1
– Especially useful for sparse address spaces (where memory 
references are non-contiguous and scattered) 
24
Hashed Page Table
This page table contains a chain of elements hashing to the same location.
Each element contains (1) the virtual page number (2) the value of the mapped   page frame  
(3) a pointer to the next element
25
Inverted Page Table
• Rather than each process having 
a page table and keeping track of 
all possible logical pages, track 
all physical pages
– One entry for each real page of 
memory
– Entry consists of the virtual 
address of the page stored in 
that real memory location, with 
information about the process 
that owns that page
Search for pid, p, offset i is the physical frame address 
26
Inverted Page Table
• Decreases memory needed to store each 
page table, but increases time needed to 
search the table when a page reference 
occurs
• But how to implement shared memory?
– One mapping of a virtual address to the 
shared physical address. Not possible.
Used in IA-64 ..
27
Segmentation Approach
Memory-management scheme that supports 
user view of memory 
• A program is a collection of segments
– A segment is a logical unit such as:
main program
procedure, function, method
object
local variables, global variables
common block
stack, arrays, symbol table
• Segment table
– Segment-table base register (STBR)
– Segment-table length register (STLR)
• segments vary in length, can very dynamically
• Segments may be paged
• Used for x86-32 bit
• Origin of term “segmentation fault”
29
Examples
• Intel IA-32 (x386-Pentium)
• x86-64 (AMD,  Intel)
• ARM
30
Logical to Physical Address Translation in IA-32
31
Intel IA-32 Paging Architecture
32
Intel IA-32 Page Address Extensions
! 32-bit address limits led Intel to create page address extension (PAE), 
allowing 32-bit apps access to more than 4GB of memory space
! Paging went to a 3-level scheme
! Top two bits refer to a page directory pointer table
! Page-directory and page-table entries moved to 64-bits in size
! Net effect is increasing address space by increasing  frame address bits. 
page directory page table offset
31 30 29 21 20 12 11 0
4-KB
page
CR3
register page directory page page
pointer table directory table
33
Intel x86-64
! Intel x86 architecture based on AMD 64 bit architecture
! 64 bits is ginormous (> 16 exabytes)
! In practice only implement 48 bit addressing or perhaps 52
" Page sizes of 4 KB, 2 MB, 1 GB
" Four levels of paging hierarchy
! Can also use PageAddressExtensions so virtual addresses are 48 
bits and physical addresses are 52 bits
page map page directory page page
unused level 4 pointer table directory table offset
63 48 47 39 38 30 29 21 20 12 11 0
Exabyte: 10246 bytes
34
Example: ARM Architecture
" Dominant mobile platform chip 
(Apple iOS and Google Android 
devices for example) 32 bits
" Modern, energy efficient, 32-bit outer page inner page offset
CPU
" 4 KB and 16 KB pages
4-KB
" 1 MB and 16 MB pages (termed or
sections) 16-KB
page
" One-level paging for sections, two-
level for smaller pages
" Two levels of TLBs 1-MB
! Outer level has two micro or16-MB 
TLBs (one data, one section
instruction)
! Inner is single main TLB
! First inner is checked, on 
miss outers are checked, 
and on miss page table 
walk performed by CPU
35
CS370 Operating Systems
Colorado State University
Yashwant K Malaiya
Spring 2020
Virtual Memory
Slides based on 
• Text by Silberschatz, Galvin, Gagne
• Various sources
36 36
Virtual Memory: Objectives
! A virtual memory system
! Demand paging, page-
replacement algorithms, 
allocation of page frames to 
processes
! Threshing, the working-set model
! Memory-mapped files and shared 
memory and
! Kernel memory allocation
38 38
Fritz-Rudolf Güntsch: Virtual Memory
Fritz-Rudolf Güntsch (1925-2012) at the 
Technische Universität Berlin in 1956 in 
his doctoral thesis, Logical Design of a 
Digital Computer with Multiple 
Asynchronous Rotating Drums and 
Automatic High Speed Memory 
Operation.
First used in Atlas, Manchester, 1962
PCs:  Windows 95 
When was Win 95 
introduced?
39
Background
• Code needs to be in memory to execute, but entire 
program rarely used
– Error code, unusual routines, large data structures
• Entire program code not needed at the same time
• Consider ability to execute partially-loaded 
program
– Program no longer constrained by limits of physical 
memory
– Each program uses less memory while running -> more 
programs run at the same time
• Increased CPU utilization and throughput with no increase in 
response time or turnaround time
– Less I/O needed to load or swap programs into memory 
-> each user program runs faster
41
Background (Cont.)
• Virtual memory – separation of user logical 
memory from physical memory
• Virtual address space – logical view of how 
process views memory
– Usually start at address 0, contiguous addresses until end of 
space
– Meanwhile, physical memory organized in page frames
– MMU must map logical to physical
• Virtual memory can be implemented via:
– Demand paging 
– Demand segmentation That is the 
new idea
42
Virtual Memory That is Larger Than Physical Memory
43
Virtual-address Space: advantages
! Usually design logical address space for 
stack to start at Max logical address and 
grow “down” while heap grows “up”
! Maximizes address space use
! Unused address space between the 
two is hole
4 No physical memory needed until heap 
or stack grows to a given new page
! Enables sparse address spaces with holes 
left for growth, dynamically linked libraries, 
etc.
! System libraries shared via mapping into 
virtual address space
! Shared memory by mapping pages read-
write into virtual address space
! Pages can be shared during fork(), 
speeding process creation
44
Shared Library Using Virtual Memory
45
Demand Paging
• Could bring entire process into memory 
at load time
• Or bring a page into memory only when it 
is needed: Demand paging
– Less I/O needed, no unnecessary I/O
– Less memory needed 
– Faster response
– More users
• Similar to paging system with swapping 
(diagram on right)
• Page is needed Þ reference to it
– invalid reference Þ abort
– not-in-memory Þ bring to memory
• “Lazy swapper” – never swaps a page 
into memory unless page will be needed
– Swapper that deals with pages is a 
pager
46
Demand paging: Basic Concepts
• Demand paging: pager brings in only those pages 
into memory what are needed
• How to determine that set of pages?
– Need new MMU functionality to implement demand 
paging
• If pages needed are already memory resident
– No difference from non-demand-paging
• If page needed and not memory resident
– Need to detect and load the page into memory from 
storage
• Without changing program behavior
• Without programmer needing to change code
47
Valid-Invalid Bit
• With each page table entry a valid–invalid bit is associated
(v Þ in-memory – memory resident, i Þ not-in-memory)
• Initially valid–invalid bit is set to i on all entries
• Example of a page table snapshot:
•
• During MMU address translation, if valid–invalid bit in page table 
entry is i Þ page fault
48
Page Table When Some Pages Are Not in Main Memory
Page 0 in Frame 4 (and disk)
Page 1 in Disk
49
Page Fault
• If there is a reference to a page, first reference to 
that page will trap to operating system: Page fault
Page fault
1. Operating system looks at a table to decide:
– Invalid reference Þ abort
– Just not in memory, but in backing storage, ->2
2. Find free frame
3. Get page into frame via scheduled disk operation
4. Reset tables to indicate page now in memory
Set validation bit = v
5. Restart the instruction that caused the page fault
Page fault: context switch because disk access is needed
50
Questions for you
• What is disk space is full, physical memory is full, and the 
user launches a process? 
• If physical memory (RAM) gets to be very big, do accesses 
to disk reduce? 
• Is there ever a case where adding more memory does not 
help? 
51
Technical Perspective: Multiprogramming
Solving a problem gives rise to a new class of problem:
• Contiguous allocation. Problem: external fragmentation
• Non-contiguous, but entire process in memory: Problem: 
Memory occupied by stuff needed only occasionally. Low 
degree of Multiprogramming.
• Demand Paging: Problem: page faults
• How to minimize page faults?
52
Steps in Handling a Page Fault
53
